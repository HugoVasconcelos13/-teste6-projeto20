{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HugoVasconcelos13/-teste6-projeto20/blob/main/PRO_C113_Project_Solution_pt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC43O4YXfmoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470f0f92-8f3d-431b-ad1c-f586a37b1899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PRO_1-1_C113_HurricaneDamageDataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ByjusBrazil/PRO_1-1_C113_HurricaneDamageDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dados de treinamento\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "# Aumento aleatório de dados (Redimensionamento, Rotação, Inversões, Zoom, Deslocamentos) usando ImageDataGenerator\n",
        "training_data_generator = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "# Diretório de Imagens\n",
        "training_image_directory = \"/content/PRO_1-1_C113_HurricaneDamageDataset/train\"\n",
        "\n",
        "# Gere arquivos de imagem aumentada\n",
        "training_augmented_images = training_data_generator.flow_from_directory(\n",
        "    training_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUbEOKzVhYMQ",
        "outputId": "2a464416-90c1-4047-f77d-0f3b56fd8d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dados de validação\n",
        "# Aumento aleatório de dados (redimensionamento) usando ImageDataGenerator\n",
        "validation_data_generator = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Diretório de Imagens\n",
        "validation_image_directory = \"/content/PRO_1-1_C113_HurricaneDamageDataset/validate\"\n",
        "\n",
        "# Gere dados aumentados pré-processados\n",
        "validation_augmented_images = validation_data_generator.flow_from_directory(\n",
        "    validation_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os3jEJB7hnvM",
        "outputId": "e0e3199c-b99f-481b-9a9a-c44ef8d53c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#etiquetas das classes\n",
        "training_augmented_images.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "0_DunWIFiEhf",
        "outputId": "188933b7-dc6c-4e5f-c2f7-2dbcdf41836a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-32848d23b15d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#etiquetas das classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_augmented_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training_augmented_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir CNN\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # Primeira camada de Convolução e Pooling\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Segunda camada de Convolução e Pooling\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Terceira camada de Convolução e Pooling\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Quarta camada de Convolução e Pooling\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Achatar (flatten) os resultados para alimentar em uma camada densa\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Camada de classificação\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "lxxfEvA-iO3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-mPX8Koujp8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vH4NmyA6jvmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_augmented_images, epochs=20,\n",
        "                    validation_data = validation_augmented_images,\n",
        "                    verbose=True)\n",
        "\n",
        "model.save(\"Hurricane_damage.h5\")"
      ],
      "metadata": {
        "id": "rcsJO70Mj371"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_augmented_images.class_indices"
      ],
      "metadata": {
        "id": "OFPU-wkpj8bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Diretório de imagens de teste\n",
        "testing_image_directory = '/content/PRO_1-1_C113_HurricaneDamageDataset/test/damage'\n",
        "\n",
        "# Todos os arquivos de imagem no diretório\n",
        "img_files = os.listdir(testing_image_directory)\n",
        "\n",
        "i= 0\n",
        "\n",
        "# Loop através de 9 arquivos de imagem\n",
        "for file in img_files[51:60]:\n",
        "\n",
        "  # caminho completo da imagem\n",
        "  img_files_path = os.path.join(testing_image_directory, file)\n",
        "\n",
        "  # carregar imagem\n",
        "  img_1 = load_img(img_files_path,target_size=(180, 180))\n",
        "\n",
        "  # converter imagem para um array\n",
        "  img_2 = img_to_array(img_1)\n",
        "\n",
        "  # incrementar a dimensão\n",
        "  img_3 = np.expand_dims(img_2, axis=0)\n",
        "\n",
        "  # prever a classe de uma imagem não vista\n",
        "  prediction = model.predict(img_3)\n",
        "  # print(prediction)\n",
        "\n",
        "  predict_class = np.argmax(prediction, axis=1)\n",
        "  # print(predict_class)\n",
        "\n",
        "  # plotar a imagem usando subimagens\n",
        "  pyplot.subplot(3, 3, i+1)\n",
        "  pyplot.imshow(img_2.astype('uint8'))\n",
        "\n",
        "  # Adicionar o rótulo da imagem com o valor previsto da classe\n",
        "  pyplot.title(predict_class[0])\n",
        "\n",
        "  # Não mostrar eixos x e y com a imagem\n",
        "  pyplot.axis('off')\n",
        "\n",
        "  i=i+1\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "-U38f_TwqzRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}